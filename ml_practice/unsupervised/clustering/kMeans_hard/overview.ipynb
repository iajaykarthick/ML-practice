{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Hard Clustering Algorithm\n",
    "\n",
    "The KMeans hard clustering algorithm is to identify clusters within an unlabeled dataset. Each cluster is defined by its centroid (center point), and each data point is assigned to the nearest centroid. The \"hard\" in hard clustering indicates that each data point is assigned to exactly one cluster.\n",
    "\n",
    "**Components of KMeans:**\n",
    "\n",
    "*Number of Points in a Cluster:* $(N_k =  \\sum_{n=1}^{N} I[z_n=k])$\n",
    "\n",
    "*Indicator function:* \n",
    "$\n",
    "I[z_n=k] =\n",
    "    \\begin{cases}\n",
    "        1 & z_n=k \\\\\n",
    "        0 & z_nâ‰ k \n",
    "    \\end{cases}\n",
    "$\n",
    "\n",
    "*Centroid or Mean of a Cluster:* $(\\mu_k = \\frac{1}{N_k} \\sum_{n=1}^{N} I[z_n = k] x_n)$\n",
    "\n",
    "*Variance of a Cluster:* $(\\sigma_k^2 = \\frac{1}{N_k} \\sum_{n=1}^{N} I[z_n = k] ||x_n - \\mu_k||^2)$\n",
    "\n",
    "**K-means Objective Function**\n",
    "\n",
    "The K-Means objective function $(L(\\mu, z))$ accounts for both the cluster centroids $(\\mu)$ and the data point assignments $(z)$. It can be expressed as:\n",
    "\n",
    "$$\n",
    "L(\\mu, z) = \\sum_{k=1}^{K} N_k \\sigma_k^2\n",
    "= \\sum_{k=1}^{K} \\sum_{n=1}^{N} I[z_n = k] || x_n - \\mu_k ||^2\n",
    "$$\n",
    "\n",
    "The goal is to minimize this loss with respect to both centroids and assignments, which can be formally stated as:\n",
    "\n",
    "$$\n",
    "\\min_{\\mu, z} L(\\mu, z)\n",
    "$$\n",
    "\n",
    "Given the combinatorial nature of the problem, with $(K^N)$ possible combinations of assignments, solving this via brute force is not computationally feasible.\n",
    "\n",
    "**Algorithm steps:**\n",
    "1. **Initialization**: Select `K` initial centroids (center point of the clusters). This can be done in several ways such as randomly, selecting the farthest points, or using the kmeans++ method.\n",
    "\n",
    "2. **Expectation-Maximization(EM) Steps**:\n",
    "    - Expectation (E-step): Determine the membership of each data point by assigning it to the cluster whose centroid is closest, based on the chosen distance or similarity metric. This step focuses on finding the best cluster assignments based on the current positions of the centroid, effectively minimizing $L(\\mu, z)$ with respect to $z$ while keeping $\\mu$ fixed.\n",
    "    - Maximization (M-step): Recalculate the centroids of each cluster as the mean of all data points currently assigned to that cluster. This effectively updates the membership criteria for the next E-step. This step focuses on finding the best positions for the centroid given the current cluster assignment, effectively minimizing $L(\\mu, z)$ with respect to $\\mu$, keeping $z$ fixed to the assignments determined in the previous E-step.\n",
    "  \n",
    "Together, the E-step and M-step iteratively improve the cluster assignments and the centroid positions, thus minimizing the overall objective function $L(\\mu, z)$.\n",
    "\n",
    "3. **Termination Criteria**:\n",
    "   The algorithm iterates between E and M steps until:\n",
    "   - The centroids do not change significantly between iterations.\n",
    "   - The decrease in the objective function from one iteration to the next is below a certain threshold (i.e., the objective function converges)\n",
    "   - A predefined number of iterations is reached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
