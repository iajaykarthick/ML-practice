{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc742312",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dbc7cc",
   "metadata": {},
   "source": [
    "\n",
    "Workflow for Decision Tree Classifier:\n",
    "\n",
    "\n",
    "1. Data Preparation:\n",
    "\n",
    "- Load the data, ensuring it's in a suitable format (e.g., list of lists).\n",
    "- Identify the feature columns and the target column (class label).\n",
    "\n",
    "2. Building the Tree:\n",
    "\n",
    "- Recursive Function build_tree(rows, header):\n",
    "  - Base Case:\n",
    "    - If information gain is 0 (no further meaningful splits), create a Leaf node with majority class prediction.\n",
    "  - Otherwise:\n",
    "    - Find the best question to split the data using find_best_split(rows, header).\n",
    "    - Partition the data into true and false branches based on the question.\n",
    "    - Recursively build subtrees for both branches.\n",
    "    - Construct a DecisionNode with the question, true branch, and false branch.\n",
    "\n",
    "3. Making Predictions:\n",
    "\n",
    "- Function `classify(row, node)`:\n",
    "  - Base Case:\n",
    "    - If a Leaf node is reached, return its predictions.\n",
    "  - Otherwise:\n",
    "    - Evaluate the Question at the current node.\n",
    "    - Recursively classify the row based on the answer (true or false branch).\n",
    "\n",
    "4. Additional Functions:\n",
    "\n",
    "- `unique_vals(rows, col)`: Returns unique values in a column.\n",
    "- `class_counts(rows, class_index=-1)`: Counts class occurrences in a dataset.\n",
    "- `numeric(value)`: Checks if a value is numeric.\n",
    "- `gini(rows)`: Calculates Gini impurity of a dataset.\n",
    "- `info_gain(left, right, current_uncertainity)`: Calculates information gain.\n",
    "- `find_best_split(rows, header)`: Finds the best question to split the data.\n",
    "- `print_tree(node, spacing=\"\")`: Visualizes the tree structure in text format.\n",
    "- `print_predictions(counts)`: Prints class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b942a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d5f5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['color', 'diameter', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef15cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_vals(rows, col):\n",
    "    return set([row[col] for row in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568173a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(rows, class_index=-1):\n",
    "    counts = {}\n",
    "    \n",
    "    for row in rows:\n",
    "        label = row[class_index]\n",
    "        if label not in counts:\n",
    "            counts[label] = 0\n",
    "        counts[label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59de84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Apple': 2, 'Grape': 2, 'Lemon': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1c37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(value):\n",
    "    return isinstance(value, int) or isinstance(value, float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e462697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        \n",
    "    def match(self, example):\n",
    "        val = example[self.column]\n",
    "        if is_numeric(val):\n",
    "            return val >= self.value\n",
    "        else:\n",
    "            return val == self.value\n",
    "        \n",
    "    def __repr__(self):\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value):\n",
    "            condition = \">=\"\n",
    "        return f\"Is {header[self.column]} {condition} {str(self.value)}?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a12c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1\n",
    "match_value = 5\n",
    "question = Question(index, match_value)\n",
    "question.match(training_data[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69cbdef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows, question):\n",
    "    true_rows, false_rows = [], []\n",
    "    \n",
    "    for row in rows:\n",
    "        if question.match(row):\n",
    "            true_rows.append(row)\n",
    "        else:\n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3cb20",
   "metadata": {},
   "source": [
    "Gini Impurity = $1 - \\displaystyle\\sum_{i-1}^{k} p_i^{2}$\n",
    "\n",
    "where k is the number of class labels and $p_i$ is the probability of samples belonging to the class $i$ at a given node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e7fc442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows):\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for label in counts:\n",
    "        prob_of_label = counts[label] / len(rows)\n",
    "        impurity -= prob_of_label**2\n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b3899",
   "metadata": {},
   "source": [
    "Calculate **Information Gain** using Gini Impurity in the context of decision tree:\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Information Gain} = \\text{uncertainty} - \\left( \\frac{|S_{\\text{left}}|}{|S|} \\times \\text{Gini}(S_{\\text{left}}) + \\frac{|S_{\\text{right}}|}{|S|} \\times \\text{Gini}(S_{\\text{right}}) \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Where:\n",
    "* $|S_{\\text{left}}|$ and $|S_{\\text{right}}|$ are the number of samples in the left and right child nodes, respectively.\n",
    "* $∣S∣$ is the total number of samples at the current node.\n",
    "* $\\text{Gini}(S)$ is the Gini impurity of node $S$.\n",
    "\n",
    "\n",
    "It calculates the information gain by subtracting the weighted impurity of two child nodes from the uncertainty(gini impurity here) of the starting node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91a67ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainity):\n",
    "    p = len(left) / (len(left) + len(right))\n",
    "    return current_uncertainity - (p * gini(left) + (1-p) * gini(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84648b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Current Uncertainity (of root node)\n",
    "current_uncertainity = gini(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d3a1c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1399999999999999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How much information do we gain by partitioning on 'Green'?\n",
    "true_rows, false_rows = partition(training_data, Question(0, 'Green'))\n",
    "info_gain(true_rows, false_rows, current_uncertainity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bafb1a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17333333333333323"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How much information do we gain by partitioning on 'Yellow'?\n",
    "true_rows, false_rows = partition(training_data, Question(0, 'Yellow'))\n",
    "info_gain(true_rows, false_rows, current_uncertainity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e489841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37333333333333324"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How much information do we gain by partitioning on 'Red'?\n",
    "true_rows, false_rows = partition(training_data, Question(0, 'Red'))\n",
    "info_gain(true_rows, false_rows, current_uncertainity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "989f4a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red\n",
      "0.37333333333333324\n",
      "{'Grape': 2} {'Apple': 2, 'Lemon': 1}\n",
      "Green\n",
      "0.1399999999999999\n",
      "{'Apple': 1} {'Apple': 1, 'Grape': 2, 'Lemon': 1}\n",
      "Yellow\n",
      "0.17333333333333323\n",
      "{'Apple': 1, 'Lemon': 1} {'Apple': 1, 'Grape': 2}\n"
     ]
    }
   ],
   "source": [
    "# It looks like we learned more using 'Red' (0.37), than 'Green' (0.14) or 'Yellow' (0.17).\n",
    "# This is because, 'Red' is better at separating 'Apple' from 'Grapes' and less number of mixed-up fruits will end up in either branch.\n",
    "\n",
    "for color in ['Red', 'Green', 'Yellow']:\n",
    "    print(color)\n",
    "    true_rows, false_rows = partition(training_data, Question(0, color))\n",
    "    print(info_gain(true_rows, false_rows, current_uncertainity))\n",
    "    print(class_counts(true_rows), class_counts(false_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7054b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows):\n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value and calculating the information gain.\"\"\"\n",
    "    best_gain = 0\n",
    "    best_question = None\n",
    "    current_uncertainity = gini(rows)\n",
    "    n_features = len(rows[0]) - 1\n",
    "    \n",
    "    for col in range(n_features):\n",
    "        values = set([row[col] for row in rows]) # Unique values in the column\n",
    "        for val in values:\n",
    "            question = Question(col, val)\n",
    "            \n",
    "            # try splitting the dataset\n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "            \n",
    "            # if it doesn't split the dataset, skip it\n",
    "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
    "                continue\n",
    "            \n",
    "            # calculate the information gain from this split\n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainity)\n",
    "            \n",
    "            if gain > best_gain:\n",
    "                best_gain, best_question = gain, question\n",
    "        \n",
    "    return best_gain, best_question\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8ea9b4aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37333333333333324, Is diameter >= 3?)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gain, best_question = find_best_split(training_data)\n",
    "best_gain, best_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "187aba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf:\n",
    "    def __init__(self, rows):       \n",
    "        self.predictions = class_counts(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e71020a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, question, true_branch, false_branch):\n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba05f85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows):\n",
    "    \n",
    "    # Try partitioning the dataset on each of the unique attributes, calculate the information gain, and return the question that produces the highest gain.\n",
    "    gain, question = find_best_split(rows)\n",
    "    \n",
    "    # Base case: no further info gain; even the best info gain is 0, we can't split any further.\n",
    "    # Since we can ask no further questions, we'll return a leaf.\n",
    "    if gain == 0:\n",
    "        return Leaf(rows)\n",
    "    \n",
    "    # TODO: Negative gain? Even though find_best_split handles negative gain cases, should I check for precision errors?\n",
    "    \n",
    "    # If we reach here, we have found a useful feature / value to partition on.\n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    \n",
    "    # Recursively build the true branch.\n",
    "    true_branch = build_tree(true_rows)\n",
    "    \n",
    "    # Recursively build the false branch.\n",
    "    false_branch = build_tree(false_rows)\n",
    "    \n",
    "    # Return a Question node.\n",
    "    # This records the best feature / value to ask at this point, as well as the branches to follow depending on the answer.\n",
    "    return DecisionNode(question, true_branch, false_branch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de22df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "    \"\"\"Prints the decision tree in an elegant format.\"\"\"\n",
    "    \n",
    "    # Base case: if we have reached a leaf node\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Predict:\", node.predictions)\n",
    "        return\n",
    "    \n",
    "    # Print the question at this node\n",
    "    print(spacing + str(node.question))\n",
    "    \n",
    "    # Print the branches\n",
    "    print(spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "    \n",
    "    print(spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44f71735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is diameter >= 3?\n",
      "--> True:\n",
      "  Is color == Yellow?\n",
      "  --> True:\n",
      "    Predict: {'Apple': 1, 'Lemon': 1}\n",
      "  --> False:\n",
      "    Predict: {'Apple': 1}\n",
      "--> False:\n",
      "  Predict: {'Grape': 2}\n"
     ]
    }
   ],
   "source": [
    "my_tree = build_tree(training_data)\n",
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ead9bc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is color == Red?\n",
      "--> True:\n",
      "  Predict: {'Grape': 2}\n",
      "--> False:\n",
      "  Is color == Yellow?\n",
      "  --> True:\n",
      "    Predict: {'Apple': 1, 'Lemon': 1}\n",
      "  --> False:\n",
      "    Predict: {'Apple': 1}\n"
     ]
    }
   ],
   "source": [
    "my_tree = build_tree(training_data)\n",
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "966a6051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Green', 3, 'Apple'],\n",
       " ['Yellow', 3, 'Apple'],\n",
       " ['Red', 1, 'Grape'],\n",
       " ['Red', 1, 'Grape'],\n",
       " ['Yellow', 3, 'Lemon']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c5fe074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node):\n",
    "    \n",
    "    # Base case: we've reached a leaf\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.predictions\n",
    "    \n",
    "    \n",
    "    # Decide whether to follow the true-branch or the false-branch\n",
    "    if node.question.match(row):\n",
    "        return classify(row, node.true_branch)\n",
    "    else:\n",
    "        return classify(row, node.false_branch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "470709b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Apple': 1}, 'True label is Apple')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(training_data[0], my_tree), \"True label is \" + str(training_data[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2cd825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa221cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(counts):\n",
    "    total = sum(counts.values())\n",
    "    probs = {}\n",
    "    for label in counts.keys():\n",
    "        probs[label] = str(int(counts[label]) * 100 / total) + \"%\"\n",
    "        \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ecf545a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Apple': '50.0%', 'Lemon': '50.0%'}, 'True label is Apple')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confidence is lower\n",
    "print_predictions(classify(training_data[1], my_tree)), \"True label is \" + str(training_data[1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b84b3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "testing_data = [\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 4, 'Apple'],\n",
    "    ['Red', 2, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7f10f9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Apple. Predicted: {'Apple': '100.0%'}\n",
      "Actual: Apple. Predicted: {'Apple': '50.0%', 'Lemon': '50.0%'}\n",
      "Actual: Grape. Predicted: {'Grape': '100.0%'}\n",
      "Actual: Grape. Predicted: {'Grape': '100.0%'}\n",
      "Actual: Lemon. Predicted: {'Apple': '50.0%', 'Lemon': '50.0%'}\n"
     ]
    }
   ],
   "source": [
    "for row in testing_data:\n",
    "    print(\"Actual: %s. Predicted: %s\" % (row[-1], print_predictions(classify(row, my_tree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aac0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
